"""
–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ Requesty AI

–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞—Ö, –º–æ–¥–µ–ª—è—Ö –∏ –∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö
"""

from dataclasses import dataclass
from typing import List, Optional


@dataclass
class ModelInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    id: str
    provider: str
    name: str
    context_window: int
    cost_per_1m_input: float  # USD
    cost_per_1m_output: float  # USD
    description: str
    best_for: List[str]


# ============================================
# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ Requesty AI
# ============================================

AVAILABLE_MODELS = {
    # OpenAI models
    "openai/gpt-4o": ModelInfo(
        id="openai/gpt-4o",
        provider="OpenAI",
        name="GPT-4o",
        context_window=128_000,
        cost_per_1m_input=2.50,
        cost_per_1m_output=10.00,
        description="–°–∞–º–∞—è –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å OpenAI",
        best_for=["reasoning", "complex_tasks", "coding", "multilingual"]
    ),
    
    "openai/gpt-4o-mini": ModelInfo(
        id="openai/gpt-4o-mini",
        provider="OpenAI",
        name="GPT-4o Mini",
        context_window=128_000,
        cost_per_1m_input=0.15,
        cost_per_1m_output=0.60,
        description="–ë—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á",
        best_for=["simple_tasks", "fast_responses", "cost_effective"]
    ),
    
    "openai/o1-mini": ModelInfo(
        id="openai/o1-mini",
        provider="OpenAI",
        name="O1 Mini",
        context_window=128_000,
        cost_per_1m_input=3.00,
        cost_per_1m_output=12.00,
        description="Reasoning –º–æ–¥–µ–ª—å —Å CoT",
        best_for=["complex_reasoning", "math", "logic"]
    ),
    
    # Anthropic models
    "anthropic/claude-3-5-sonnet-20241022": ModelInfo(
        id="anthropic/claude-3-5-sonnet-20241022",
        provider="Anthropic",
        name="Claude 3.5 Sonnet",
        context_window=200_000,
        cost_per_1m_input=3.00,
        cost_per_1m_output=15.00,
        description="–õ—É—á—à–∏–π reasoning —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π",
        best_for=["reasoning", "analysis", "long_context", "coding"]
    ),
    
    "anthropic/claude-3-5-haiku-20241022": ModelInfo(
        id="anthropic/claude-3-5-haiku-20241022",
        provider="Anthropic",
        name="Claude 3.5 Haiku",
        context_window=200_000,
        cost_per_1m_input=0.80,
        cost_per_1m_output=4.00,
        description="–ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å Anthropic",
        best_for=["fast_responses", "simple_tasks", "cost_effective"]
    ),
    
    # Google models
    "google/gemini-1.5-pro": ModelInfo(
        id="google/gemini-1.5-pro",
        provider="Google",
        name="Gemini 1.5 Pro",
        context_window=2_000_000,  # 2M tokens!
        cost_per_1m_input=1.25,
        cost_per_1m_output=5.00,
        description="–û–≥—Ä–æ–º–Ω—ã–π context window –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
        best_for=["long_documents", "video", "multimodal"]
    ),
    
    "google/gemini-1.5-flash": ModelInfo(
        id="google/gemini-1.5-flash",
        provider="Google",
        name="Gemini 1.5 Flash",
        context_window=1_000_000,
        cost_per_1m_input=0.075,
        cost_per_1m_output=0.30,
        description="–û—á–µ–Ω—å –¥–µ—à–µ–≤–∞—è –º–æ–¥–µ–ª—å —Å –±–æ–ª—å—à–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
        best_for=["cost_effective", "long_documents", "fast_responses"]
    ),
}


# ============================================
# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –Ω–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
# ============================================

RECOMMENDED_MODELS = {
    "agent_b_outline": [
        "openai/gpt-4o-mini",  # –û—Å–Ω–æ–≤–Ω–∞—è: –¥–µ—à–µ–≤–æ, –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
        "anthropic/claude-3-5-haiku-20241022",  # Fallback: –±—ã—Å—Ç—Ä–æ
        "google/gemini-1.5-flash",  # Backup: –æ—á–µ–Ω—å –¥–µ—à–µ–≤–æ
    ],
    
    "agent_b_complex": [
        "openai/gpt-4o",  # –û—Å–Ω–æ–≤–Ω–∞—è: —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
        "anthropic/claude-3-5-sonnet-20241022",  # Fallback: –ª—É—á—à–∏–π reasoning
    ],
    
    "agent_c_compiler": [
        "openai/gpt-4o-mini",  # –û—Å–Ω–æ–≤–Ω–∞—è: —à–∞–±–ª–æ–Ω—ã
        "google/gemini-1.5-flash",  # Fallback: –¥–µ—à–µ–≤–æ
    ],
    
    "agent_d_qa": [
        "anthropic/claude-3-5-sonnet-20241022",  # –û—Å–Ω–æ–≤–Ω–∞—è: –ª—É—á—à–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        "openai/gpt-4o",  # Fallback: —Ç–æ–∂–µ —Ö–æ—Ä–æ—à
    ],
}


def get_model_info(model_id: str) -> Optional[ModelInfo]:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
    return AVAILABLE_MODELS.get(model_id)


def list_models(provider: Optional[str] = None) -> List[ModelInfo]:
    """
    –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É)
    
    Args:
        provider: –§–∏–ª—å—Ç—Ä –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É (OpenAI, Anthropic, Google)
        
    Returns:
        –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
    """
    models = list(AVAILABLE_MODELS.values())
    
    if provider:
        models = [m for m in models if m.provider.lower() == provider.lower()]
    
    return models


def estimate_cost(
    model_id: str,
    input_tokens: int,
    output_tokens: int
) -> Optional[float]:
    """
    –û—Ü–µ–Ω–∏—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞
    
    Args:
        model_id: ID –º–æ–¥–µ–ª–∏
        input_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ input —Ç–æ–∫–µ–Ω–æ–≤
        output_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ output —Ç–æ–∫–µ–Ω–æ–≤
        
    Returns:
        –°—Ç–æ–∏–º–æ—Å—Ç—å –≤ USD
    """
    model = get_model_info(model_id)
    
    if not model:
        return None
    
    cost_input = (input_tokens / 1_000_000) * model.cost_per_1m_input
    cost_output = (output_tokens / 1_000_000) * model.cost_per_1m_output
    
    return cost_input + cost_output


if __name__ == "__main__":
    # –¢–µ—Å—Ç
    print("üìä Available Models:\n")
    
    for model_id, model in AVAILABLE_MODELS.items():
        print(f"ü§ñ {model.name} ({model.provider})")
        print(f"   ID: {model.id}")
        print(f"   Context: {model.context_window:,} tokens")
        print(f"   Cost: ${model.cost_per_1m_input:.2f}/${model.cost_per_1m_output:.2f} per 1M tokens")
        print(f"   Best for: {', '.join(model.best_for)}")
        print()
    
    # –ü—Ä–∏–º–µ—Ä –æ—Ü–µ–Ω–∫–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
    print("üí∞ Cost Estimation Example:")
    cost = estimate_cost("openai/gpt-4o-mini", input_tokens=10_000, output_tokens=5_000)
    print(f"   10K input + 5K output tokens = ${cost:.4f}")
    
    print("\nüéØ Recommended Models for Agent B:")
    for model_id in RECOMMENDED_MODELS["agent_b_outline"]:
        model = get_model_info(model_id)
        print(f"   - {model.name} ({model.provider})")
