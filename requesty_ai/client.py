"""
Requesty AI Client —Å –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ retry –ª–æ–≥–∏–∫–æ–π

–û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö –∏–∑ inputs/agent_1_2.md (—Å—Ç—Ä–æ–∫–∏ 640+)
"""

import os
import openai
from dotenv import load_dotenv
import time
from typing import Optional, List, Dict, Iterator
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()


class RequestyClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Requesty AI Gateway
    
    Features:
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π retry —Å exponential backoff
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫ (rate limits, timeouts, connection)
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ streaming
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        base_url: str = "https://router.requesty.ai/v1",
        timeout: int = 60,
        max_retries: int = 3
    ):
        """
        Args:
            api_key: Requesty API key (–µ—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑ REQUESTY_API_KEY)
            base_url: –ë–∞–∑–æ–≤—ã–π URL Requesty API
            timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            max_retries: –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        """
        self.api_key = api_key or os.getenv("REQUESTY_API_KEY")
        
        if not self.api_key:
            raise ValueError(
                "‚ùå REQUESTY_API_KEY not found. "
                "Set it in .env file or pass to constructor."
            )
        
        self.base_url = base_url
        self.timeout = timeout
        self.max_retries = max_retries
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
        self.client = openai.OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=self.timeout,
            default_headers={
                "HTTP-Referer": os.getenv("SITE_URL", "https://example.com"),
                "X-Title": os.getenv("SITE_NAME", "My AI App"),
            }
        )
        
        logger.info(f"‚úÖ RequestyClient initialized (base_url={base_url})")
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        model: str = "openai/gpt-4o-mini",
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Optional[str]:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ chat completion –∑–∞–ø—Ä–æ—Å–∞ —Å retry –ª–æ–≥–∏–∫–æ–π
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π [{role, content}, ...]
            model: ID –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ provider/model
            temperature: Temperature –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0-2)
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è API
            
        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        for attempt in range(1, self.max_retries + 1):
            try:
                logger.info(f"üîÑ Attempt {attempt}/{self.max_retries} (model={model})")
                
                # –ó–∞–ø—Ä–æ—Å –∫ API
                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                    **kwargs
                )
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –æ—Ç–≤–µ—Ç–∞
                if not response.choices:
                    raise ValueError("‚ùå API returned empty response")
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                content = response.choices[0].message.content
                
                if not content or content.strip() == "":
                    raise ValueError("‚ùå API returned empty content")
                
                # –£—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                logger.info(f"‚úÖ Success on attempt {attempt}")
                
                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                if hasattr(response, 'usage'):
                    logger.info(
                        f"üìä Tokens used: "
                        f"prompt={response.usage.prompt_tokens}, "
                        f"completion={response.usage.completion_tokens}, "
                        f"total={response.usage.total_tokens}"
                    )
                
                return content
            
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ OpenAI API
            except openai.AuthenticationError as e:
                logger.error(f"‚ùå Authentication Error: {e}")
                logger.error("   Check your REQUESTY_API_KEY")
                return None  # –ù–µ —Ä–µ—Ç—Ä–∞–∏–º, –∫–ª—é—á –Ω–µ–≤–µ—Ä–Ω—ã–π
            
            except openai.RateLimitError as e:
                logger.warning(f"‚ö†Ô∏è Rate Limit Error: {e}")
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt  # Exponential backoff: 2, 4, 8 —Å–µ–∫
                    logger.info(f"   Waiting {wait_time}s before retry...")
                    time.sleep(wait_time)
                else:
                    logger.error("   Max retries reached")
                    return None
            
            except openai.APITimeoutError as e:
                logger.warning(f"‚è±Ô∏è Timeout Error: {e}")
                if attempt < self.max_retries:
                    logger.info(f"   Retrying (attempt {attempt + 1})...")
                else:
                    logger.error("   Max retries reached")
                    return None
            
            except openai.APIConnectionError as e:
                logger.warning(f"üåê Connection Error: {e}")
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt
                    logger.info(f"   Waiting {wait_time}s before retry...")
                    time.sleep(wait_time)
                else:
                    logger.error("   Max retries reached")
                    return None
            
            except openai.APIError as e:
                logger.warning(f"‚ö†Ô∏è API Error: {e}")
                if attempt < self.max_retries:
                    logger.info(f"   Retrying (attempt {attempt + 1})...")
                else:
                    logger.error("   Max retries reached")
                    return None
            
            # –û–±—â–∏–µ –æ—à–∏–±–∫–∏
            except ValueError as e:
                logger.error(f"‚ùå Validation Error: {e}")
                return None  # –ù–µ —Ä–µ—Ç—Ä–∞–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
            
            except Exception as e:
                logger.error(f"‚ùå Unexpected Error: {type(e).__name__}: {e}")
                if attempt < self.max_retries:
                    logger.info(f"   Retrying (attempt {attempt + 1})...")
                else:
                    logger.error("   Max retries reached")
                    return None
        
        return None  # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
    
    def chat_stream(
        self,
        messages: List[Dict[str, str]],
        model: str = "openai/gpt-4o-mini",
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Iterator[str]:
        """
        Streaming chat completion (–¥–ª—è real-time –≤—ã–≤–æ–¥–∞)
        
        Args:
            messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
            model: ID –º–æ–¥–µ–ª–∏
            temperature: Temperature
            max_tokens: –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Yields:
            –ß–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        try:
            logger.info(f"üîÑ Starting stream (model={model})")
            
            stream = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True,
                **kwargs
            )
            
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
            
            logger.info("‚úÖ Stream completed")
        
        except Exception as e:
            logger.error(f"‚ùå Streaming error: {e}")
            yield f"\n\n‚ùå Error: {e}"


# ============================================
# Convenience —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================

def chat_with_retry(
    messages: List[Dict[str, str]],
    model: str = "openai/gpt-4o-mini",
    max_retries: int = 3,
    timeout: int = 60,
    **kwargs
) -> Optional[str]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        model: ID –º–æ–¥–µ–ª–∏
        max_retries: –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫
        timeout: –¢–∞–π–º–∞—É—Ç
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        
    Returns:
        –û—Ç–≤–µ—Ç –∏–ª–∏ None
    """
    client = RequestyClient(max_retries=max_retries, timeout=timeout)
    return client.chat(messages, model=model, **kwargs)


def chat_with_streaming(
    messages: List[Dict[str, str]],
    model: str = "openai/gpt-4o-mini",
    **kwargs
) -> str:
    """
    Streaming —Å –≤—ã–≤–æ–¥–æ–º –≤ –∫–æ–Ω—Å–æ–ª—å
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        model: ID –º–æ–¥–µ–ª–∏
        **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        
    Returns:
        –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
    """
    client = RequestyClient()
    full_response = ""
    
    for chunk in client.chat_stream(messages, model=model, **kwargs):
        print(chunk, end="", flush=True)
        full_response += chunk
    
    print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞
    return full_response


if __name__ == "__main__":
    # –¢–µ—Å—Ç
    print("üß™ Testing Requesty AI Client\n")
    
    messages = [
        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Ñ–∏–Ω–∞–Ω—Å–∞–º."},
        {"role": "user", "content": "–ß—Ç–æ —Ç–∞–∫–æ–µ –û–°–í –≤ –±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏–∏? –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ."}
    ]
    
    # –û–±—ã—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    print("üìù Regular chat:")
    response = chat_with_retry(messages, model="openai/gpt-4o-mini")
    
    if response:
        print(f"\n‚úÖ Response:\n{response}\n")
    else:
        print("\n‚ùå Failed to get response\n")
    
    # Streaming
    print("üìù Streaming chat:")
    full_response = chat_with_streaming(messages, model="openai/gpt-4o-mini")
    print(f"\n‚úÖ Full response received ({len(full_response)} chars)\n")
