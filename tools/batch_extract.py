#!/usr/bin/env python3
"""
Batch processor Ð´Ð»Ñ Agent A
ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð²ÑÐµ ÐºÐ½Ð¸Ð³Ð¸ Ð¸Ð· S3 Ð¸ ÐºÐµÑˆÐ°
"""

import sys
from pathlib import Path
from typing import List, Dict
import json

from pipeline.agents.extractor import process_document


def process_cached_books(cache_dir: Path = Path('cache/books')) -> List[Dict]:
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²ÑÐµ ÐºÐ½Ð¸Ð³Ð¸ Ð¸Ð· cache/books/"""
    
    if not cache_dir.exists():
        print(f"âŒ Cache directory not found: {cache_dir}")
        return []
    
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ñ„Ð°Ð¹Ð»Ñ‹
    files = list(cache_dir.glob('*'))
    books = [f for f in files if f.is_file() and not f.name.startswith('.')]
    
    print(f"ðŸ“š Found {len(books)} books in cache\n")
    
    results = []
    
    for i, book_path in enumerate(books, 1):
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÐ¼ book_id Ð¸Ð· Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°
        book_id = book_path.stem.lower().replace(' ', '-').replace('+', '-')
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¾Ñ‚ ÑÐ¿ÐµÑ†ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
        book_id = ''.join(c for c in book_id if c.isalnum() or c == '-')
        
        output_dir = Path('sources') / book_id
        
        print(f"\n{'='*70}")
        print(f"[{i}/{len(books)}] Processing: {book_path.name}")
        print(f"Book ID: {book_id}")
        print(f"Output: {output_dir}")
        print(f"{'='*70}\n")
        
        try:
            result = process_document(
                input_path=book_path,
                output_dir=output_dir,
                book_id=book_id,
                use_markitdown=True
            )
            
            # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
            metadata_file = output_dir / 'metadata.json'
            metadata = json.loads(metadata_file.read_text())
            
            results.append({
                'book_id': book_id,
                'filename': book_path.name,
                'status': 'success',
                'method': metadata.get('method', 'unknown'),
                'lines': metadata.get('lines', 0),
                'format': book_path.suffix,
                'text_file': result['text_file'],
            })
            
            print(f"\nâœ… SUCCESS:")
            print(f"   Method: {metadata.get('method')}")
            print(f"   Lines: {metadata.get('lines')}")
            print(f"   Quality: {metadata.get('quality', 'N/A')}")
            if result['tables_count']:
                print(f"   Tables: {result['tables_count']}")
            if result['formulas_count']:
                print(f"   Formulas: {result['formulas_count']}")
            
        except Exception as e:
            print(f"\nâŒ FAILED: {e}")
            results.append({
                'book_id': book_id,
                'filename': book_path.name,
                'status': 'failed',
                'error': str(e),
                'format': book_path.suffix,
            })
    
    return results


def print_summary(results: List[Dict]):
    """ÐÐ°Ð¿ÐµÑ‡Ð°Ñ‚Ð°Ñ‚ÑŒ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚"""
    
    print("\n" + "="*70)
    print("ðŸ“Š PROCESSING SUMMARY")
    print("="*70 + "\n")
    
    success = [r for r in results if r['status'] == 'success']
    failed = [r for r in results if r['status'] == 'failed']
    
    print(f"Total: {len(results)}")
    print(f"âœ… Success: {len(success)}")
    print(f"âŒ Failed: {len(failed)}\n")
    
    if success:
        print("âœ… Successfully processed:\n")
        for r in success:
            print(f"  - {r['book_id']:40} | {r['method']:15} | {r['lines']:6} lines | {r['format']}")
    
    if failed:
        print("\nâŒ Failed to process:\n")
        for r in failed:
            print(f"  - {r['book_id']:40} | {r['format']:6} | Error: {r['error'][:50]}")
    
    # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ð¼ÐµÑ‚Ð¾Ð´Ð°Ð¼
    if success:
        methods = {}
        for r in success:
            method = r['method']
            methods[method] = methods.get(method, 0) + 1
        
        print("\nðŸ“ˆ Methods used:\n")
        for method, count in sorted(methods.items()):
            print(f"  - {method:20}: {count} files")
    
    # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð°Ð¼
    formats = {}
    for r in results:
        fmt = r['format']
        status = r['status']
        if fmt not in formats:
            formats[fmt] = {'success': 0, 'failed': 0}
        formats[fmt][status] += 1
    
    print("\nðŸ“ Formats:\n")
    for fmt, counts in sorted(formats.items()):
        total = counts['success'] + counts['failed']
        success_rate = (counts['success'] / total * 100) if total else 0
        print(f"  - {fmt:10}: {counts['success']}/{total} ({success_rate:.0f}% success)")


def main():
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ"""
    
    print("ðŸš€ Agent A: Batch Document Extractor")
    print("="*70 + "\n")
    
    # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²ÑÐµ ÐºÐ½Ð¸Ð³Ð¸
    results = process_cached_books()
    
    # ÐÐ°Ð¿ÐµÑ‡Ð°Ñ‚Ð°Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚
    print_summary(results)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¾Ñ‚Ñ‡ÐµÑ‚
    report_file = Path('sources/extraction_report.json')
    report_file.parent.mkdir(parents=True, exist_ok=True)
    report_file.write_text(json.dumps(results, indent=2, ensure_ascii=False))
    print(f"\nðŸ’¾ Report saved to: {report_file}")
    
    # Exit code
    failed_count = len([r for r in results if r['status'] == 'failed'])
    sys.exit(1 if failed_count > 0 else 0)


if __name__ == '__main__':
    main()
