[
  {
    "title": "Implement Agent Pipeline Architecture",
    "body": "## Цель\n\nСоздать пайплайн из специализированных AI-агентов для автоматической обработки книг и генерации методик.\n\n## Архитектура пайплайна\n\n### Агент A - Ingest/Extractor\n- **Задача**: Конвертация файлов в единый формат (текст + метаданные)\n- **Входы**: PDF, DOCX, PPTX, HTML, сканы\n- **Выходы**: `sources/<book_id>/raw_text.md` + `metadata.json`\n- **Инструменты**: pymupdf, pdfplumber, python-docx, Unstructured.io\n\n### Агент B - Outline Builder\n- **Задача**: Создание карты методологии из источника\n- **Выход**: `work/<id>/outline.yaml` с секциями: stages, tools, indicators, rules\n- **Требования**: Цитирование источников (глава/страница)\n\n### Агент C - Compiler\n- **Задача**: Генерация файлов по шаблонам на основе outline\n- **Выходы**: `docs/methodologies/<id>/*.md`, `data/methodologies/<id>.yaml`\n- **Правило**: Не придумывать, заполнять шаблон\n\n### Агент D - QA/Reviewer\n- **Задача**: Проверка качества и целостности\n- **Проверки**:\n  - Наличие всех обязательных файлов\n  - Согласованность methodology_id\n  - Валидация glossary_terms\n  - Запуск validate_glossary.py\n- **Выход**: `work/<id>/qa_report.md` + список правок\n\n### Агент E - PR Publisher (опционально)\n- Создание ветки\n- Коммит файлов\n- Открытие PR с QA report\n- Добавление labels/milestone\n\n## Структура директорий\n\n```\npipeline/\n  ├── agents/\n  │   ├── extractor.py\n  │   ├── outline_builder.py\n  │   ├── compiler.py\n  │   ├── qa_reviewer.py\n  │   └── pr_publisher.py\n  ├── prompts/\n  │   ├── extractor_prompt.md\n  │   ├── outline_prompt.md\n  │   ├── compiler_prompt.md\n  │   └── qa_prompt.md\n  ├── schemas/\n  │   ├── outline_schema.py (pydantic)\n  │   └── methodology_schema.py\n  └── cli.py\n\nwork/\n  └── <methodology_id>/\n      ├── outline.yaml\n      ├── qa_report.md\n      └── artifacts/\n```\n\n## Критерии готовности\n\n- [ ] Все 4 основных агента реализованы\n- [ ] Pipeline запускается через CLI\n- [ ] Успешно обработана хотя бы одна книга из S3\n- [ ] QA агент интегрирован с validate_glossary.py\n- [ ] Документация по запуску в `pipeline/README.md`\n\n## Связанные issues\n\n- Depends on: #18 (System Prompt для агентов)\n- Related to: #19 (OCR pipeline), #20 (LangGraph интеграция)",
    "labels": ["enhancement", "ai-agents", "pipeline"],
    "milestone": "Agent Pipeline v0.5"
  },
  {
    "title": "Create AI Methodologist System Prompt",
    "body": "## Цель\n\nРазработать универсальный system prompt для AI-методолога, который будет использоваться всеми агентами пайплайна.\n\n## Ключевые принципы (из agent.md)\n\n### 1. Роль агента\n- **НЕ**: Учитель, популяризатор, консультант\n- **ДА**: Методолог, системный архитектор знаний, компилятор методологий\n\n### 2. Основные правила\n1. НЕ придумывать новые концепции\n2. НЕ смешивать методологию и модель\n3. НЕ писать произвольные формулировки\n4. ВСЕГДА использовать глоссарий проекта\n5. Предлагать добавление новых терминов, не использовать молча\n6. Все сущности машиночитаемы (ID, YAML, чёткие связи)\n\n### 3. Структура методологии (канон)\n\nЛюбая методология описывается как:\n1. Диагностика\n2. Переосмысление финансовой логики\n3. Смена управленческого фокуса\n4. Инструменты моделирования (если есть)\n5. Планирование и управление\n\n### 4. Разделение понятий\n\n- **Методология** = логика управления (как управлять бизнесом)\n- **Модель** = инструмент принятия решений (что будет если...)\n- **Modeling Tool** = реализация модели (таблица, калькулятор)\n\nПример:\n- Power of One — МЕТОДОЛОГИЯ\n- Power of One (+1%) — ИНСТРУМЕНТ МОДЕЛИРОВАНИЯ\n\n### 5. Форматы выхода\n\nАгент генерирует ТОЛЬКО:\n- `outline.yaml`\n- `methodology.md` (по шаблону)\n- `methodology.yaml` (паспорт)\n- `indicators/*.yaml`\n- `rules/*.yaml`\n- `modeling_tools/*.yaml`\n- `qa_report.md`\n\nНикаких эссе, учебных текстов, рассуждений.\n\n## Задачи\n\n- [ ] Создать файл `pipeline/prompts/system_prompt.md`\n- [ ] Включить все принципы из agent.md\n- [ ] Добавить примеры правильного/неправильного поведения\n- [ ] Протестировать на 2-3 книгах\n- [ ] Документировать использование в агентах\n\n## Связанные issues\n\n- Required for: #17 (Agent Pipeline)\n- Related to: #8 (Glossary validation)",
    "labels": ["documentation", "ai-agents", "prompts"],
    "milestone": "Agent Pipeline v0.5"
  },
  {
    "title": "Implement OCR Pipeline for Scanned Documents",
    "body": "## Цель\n\nРеализовать обработку отсканированных документов (PDF без текстового слоя) с помощью OCR.\n\n## Варианты решения\n\n### Вариант A: Unstructured.io (рекомендуется)\n\n**Плюсы:**\n- Универсальная обработка всех форматов\n- Автоопределение типа документа\n- Извлечение таблиц и структуры\n- Поддержка русского языка\n\n```python\nfrom unstructured.partition.auto import partition\n\nelements = partition(\n    filename=file_path,\n    strategy=\"hi_res\",\n    ocr_languages=\"rus+eng\",\n    infer_table_structure=True\n)\n```\n\n### Вариант B: DocTR + Tesseract\n\n**Плюсы:**\n- Лучше для низкокачественных сканов\n- Открытый исходный код\n- Поддержка GPU\n\n```python\nfrom doctr.io import DocumentFile\nfrom doctr.models import ocr_predictor\n\nmodel = ocr_predictor(pretrained=True)\ndoc = DocumentFile.from_pdf(pdf_path)\nresult = model(doc)\n```\n\n## Интеграция с пайплайном\n\n1. Extractor Agent определяет тип PDF (текстовый/скан)\n2. Для сканов применяется OCR\n3. Результат нормализуется в единый формат\n4. Передаётся Outline Builder для структурирования\n\n## Структура обработки\n\n```\ningest/\n  <source_id>/\n    manifest.json\n    raw/\n      book.pdf\n    extracted/\n      text.md\n      tables/\n        table_001.csv\n        table_002.csv\n      images/\n        page_001.png\n```\n\n## Критерии готовности\n\n- [ ] Выбран основной OCR движок\n- [ ] Реализована обработка PDF\n- [ ] Реализована обработка DOCX\n- [ ] Реализована обработка PPTX\n- [ ] Извлечение таблиц работает\n- [ ] Поддержка русского и английского языков\n- [ ] Интеграция с Extractor Agent\n- [ ] Документация по использованию\n\n## Зависимости\n\n```txt\nunstructured[all-docs]  # Вариант A\npython-doctr[torch]     # Вариант B\npytesseract\npdf2image\nPillow\npymupdf\npdfplumber\npython-docx\n```",
    "labels": ["enhancement", "ocr", "document-processing"],
    "milestone": "Agent Pipeline v0.5"
  },
  {
    "title": "Integrate LangGraph for Methodology Structuring",
    "body": "## Цель\n\nИспользовать LangGraph для построения графа обработки документов в методики.\n\n## Архитектура графа\n\n```python\nDocumentState:\n  raw_text: str\n  document_type: str  # 'standard', 'guide', 'manual', 'presentation'\n  extracted_sections: List[dict]\n  methodology: dict\n  embeddings: List[float]\n  status: str\n```\n\n## Узлы графа\n\n### 1. Classify Document\n- Определяет тип документа\n- Используется для выбора шаблона\n\n### 2. Extract Sections\n- Разбивает на логические секции\n- Типы: definition, example, rule, table, formula\n\n### 3. Generate Methodology\n- Создаёт методику по шаблону\n- Шаблон зависит от типа документа\n\n### 4. Create Embeddings\n- Генерирует векторы для RAG\n- Модель: paraphrase-multilingual-MiniLM-L12-v2\n\n## Граф выполнения\n\n```\nclassify → extract_sections → generate_methodology → create_embeddings → END\n```\n\n## Интеграция с GigaChat\n\n```python\nfrom gigachat import GigaChat\n\ngigachat = GigaChat(\n    credentials=os.getenv('GIGACHAT_API_KEY'),\n    scope='GIGACHAT_API_PERS'\n)\n\nresponse = gigachat.chat([{\n    'role': 'system',\n    'content': system_prompt\n}, {\n    'role': 'user',\n    'content': user_prompt\n}])\n```\n\n## Критерии готовности\n\n- [ ] LangGraph граф реализован\n- [ ] Все 4 узла работают\n- [ ] Интеграция с GigaChat\n- [ ] Генерация embeddings\n- [ ] Обработка разных типов документов\n- [ ] Обработка ошибок и retry logic\n- [ ] Логирование состояний\n- [ ] Unit тесты для каждого узла\n\n## Зависимости\n\n```txt\nlanggraph\ngigachat\nsentence-transformers\npyyaml\n```\n\n## Связанные issues\n\n- Part of: #17 (Agent Pipeline)\n- Required for: #21 (ArangoDB integration)",
    "labels": ["enhancement", "ai-agents", "langgraph"],
    "milestone": "Agent Pipeline v0.5"
  },
  {
    "title": "Implement ArangoDB Knowledge Base Storage",
    "body": "## Цель\n\nСоздать систему хранения методик в ArangoDB с поддержкой графовых связей и векторного поиска.\n\n## Схема графовой БД\n\n### Коллекции вершин (vertices)\n\n1. **methodologies**\n   - `_key`: methodology_id\n   - `title`: название\n   - `type`: тип документа\n   - `sections`: массив секций\n   - `embeddings`: векторы для RAG\n   - `source_file`: ссылка на S3\n   - `created_at`: дата создания\n\n2. **indicators**\n   - `_key`: indicator_id\n   - `name`: название показателя\n   - `formula`: формула расчёта\n   - `unit`: единица измерения\n\n3. **rules**\n   - `_key`: rule_id\n   - `condition`: условие (if)\n   - `action`: действие (then)\n   - `priority`: приоритет\n\n4. **terms**\n   - `_key`: term_id\n   - `name`: термин\n   - `definition`: определение\n   - `context`: контекст использования\n\n### Коллекции рёбер (edges)\n\n1. **uses** - методология использует индикатор\n2. **depends_on** - индикатор зависит от другого\n3. **related_to** - связь между методиками\n4. **defines** - методика определяет термин\n5. **references** - ссылка на источник\n\n## Векторный поиск\n\n```python\ndef find_similar_methodologies(query_embedding: list, limit: int = 5):\n    \"\"\"\n    Поиск похожих методик по эмбеддингам\n    Используя ArangoSearch с косинусным расстоянием\n    \"\"\"\n    aql = \"\"\"\n    FOR doc IN methodologies_view\n      SEARCH ANALYZER(doc.embeddings IN @query_embedding, 'text_en')\n      SORT BM25(doc) DESC\n      LIMIT @limit\n      RETURN doc\n    \"\"\"\n    return db.aql.execute(aql, bind_vars={\n        'query_embedding': query_embedding,\n        'limit': limit\n    })\n```\n\n## Графовые запросы\n\n### Найти все индикаторы методики\n\n```aql\nFOR v, e, p IN 1..2 OUTBOUND 'methodologies/power_of_one' uses\n  RETURN v\n```\n\n### Найти зависимости индикатора\n\n```aql\nFOR v, e, p IN 1..5 OUTBOUND 'indicators/working_capital_days' depends_on\n  RETURN {indicator: v, path: p}\n```\n\n### Найти связанные методики\n\n```aql\nFOR v IN 1..1 OUTBOUND 'methodologies/cash_flow_story' related_to\n  RETURN v\n```\n\n## API для работы с БД\n\n```python\nclass KnowledgeBase:\n    def save_methodology(self, methodology: dict, embeddings: list)\n    def find_by_term(self, term: str) -> List[dict]\n    def get_methodology_graph(self, methodology_id: str) -> dict\n    def find_similar(self, text: str, limit: int) -> List[dict]\n    def validate_integrity(self) -> List[str]  # проверка связей\n```\n\n## Критерии готовности\n\n- [ ] Схема коллекций создана\n- [ ] Индексы для векторного поиска\n- [ ] API класс реализован\n- [ ] Миграция данных из текущих YAML\n- [ ] Графовые запросы работают\n- [ ] Векторный поиск работает\n- [ ] Документация по API\n- [ ] Примеры использования\n\n## Зависимости\n\n```txt\npython-arango\nsentence-transformers\n```\n\n## Связанные issues\n\n- Depends on: #20 (LangGraph embeddings)\n- Related to: #9 (Graph schema)",
    "labels": ["enhancement", "database", "arango", "rag"],
    "milestone": "Integration v0.3"
  },
  {
    "title": "Setup GitHub Actions for Automated Pipeline",
    "body": "## Цель\n\nАвтоматизировать запуск пайплайна обработки книг из S3.\n\n## Триггеры\n\n1. **Manual dispatch** - ручной запуск\n2. **Schedule** - каждое воскресенье в 2 AM\n3. **On push** к `books/` в S3 (через webhook)\n\n## Workflow steps\n\n1. Checkout repository\n2. Setup Python 3.11\n3. Install dependencies (including OCR tools)\n4. Run pipeline: `python main_pipeline.py`\n5. Commit generated methodologies\n6. Open PR with results\n7. Notify on success/failure\n\n## Secrets configuration\n\n```yaml\nYC_ACCESS_KEY: ${{ secrets.YC_ACCESS_KEY }}\nYC_SECRET_KEY: ${{ secrets.YC_SECRET_KEY }}\nGIGACHAT_API_KEY: ${{ secrets.GIGACHAT_API_KEY }}\nARANGO_HOST: ${{ secrets.ARANGO_HOST }}\nARANGO_PASSWORD: ${{ secrets.ARANGO_PASSWORD }}\n```\n\n## Артефакты\n\n- Сгенерированные методики (MD/YAML)\n- QA отчёты\n- Логи обработки\n- Метрики (время, успешность)\n\n## Критерии готовности\n\n- [ ] Workflow файл создан\n- [ ] Secrets настроены\n- [ ] Успешный тестовый запуск\n- [ ] PR автоматически создаётся\n- [ ] Нотификации работают\n- [ ] Документация по использованию\n\n## Связанные issues\n\n- Depends on: #17 (Agent Pipeline)\n- Related to: #23 (Monitoring)",
    "labels": ["automation", "ci-cd", "github-actions"],
    "milestone": "Agent Pipeline v0.5"
  },
  {
    "title": "Implement Pipeline Monitoring and Metrics",
    "body": "## Цель\n\nДобавить мониторинг работы пайплайна и сбор метрик.\n\n## Метрики\n\n### Производительность\n- Время обработки одного документа\n- Время работы каждого агента\n- Использование памяти\n- Количество API вызовов (GigaChat)\n\n### Качество\n- % успешно обработанных документов\n- Количество ошибок валидации\n- Покрытие глоссарием (% использованных терминов)\n- Количество новых терминов\n\n### Бизнес-метрики\n- Количество созданных методик\n- Количество извлечённых индикаторов\n- Количество правил (rules)\n- Размер knowledge base\n\n## Dashboard\n\n```python\nclass PipelineMetrics:\n    def track_processing_time(self, agent: str, duration: float)\n    def track_success(self, methodology_id: str)\n    def track_error(self, error: Exception, context: dict)\n    def track_glossary_coverage(self, used_terms: int, total_terms: int)\n    \n    def generate_report(self) -> dict:\n        return {\n            'total_processed': ...,\n            'success_rate': ...,\n            'avg_processing_time': ...,\n            'errors': [...]\n        }\n```\n\n## Логирование\n\n- Структурированные логи (JSON)\n- Уровни: DEBUG, INFO, WARNING, ERROR\n- Контекст: methodology_id, agent, step\n\n## Критерии готовности\n\n- [ ] Класс PipelineMetrics реализован\n- [ ] Интеграция с агентами\n- [ ] Логирование настроено\n- [ ] Dashboard/отчёт генерируется\n- [ ] Alerts при критических ошибках\n- [ ] Документация\n\n## Связанные issues\n\n- Related to: #22 (GitHub Actions)",
    "labels": ["monitoring", "metrics", "observability"],
    "milestone": "Agent Pipeline v0.5"
  }
]
